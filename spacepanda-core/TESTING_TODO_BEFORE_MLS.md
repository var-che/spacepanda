# üîí MISSION-CRITICAL TEST SUITE BEFORE CORE_MLS

**STATUS:** NOT STARTED  
**DEADLINE:** Before any MLS integration work begins  
**PRIORITY:** BLOCKING - MLS integration is catastrophically brittle without these foundations

---

## ‚ö†Ô∏è **WHY THIS MATTERS**

MLS (Messaging Layer Security) depends on:

- ‚úÖ Identity correctness (key rotation, revocation, isolation)
- ‚úÖ CRDT determinism (convergence under all conditions)
- ‚úÖ DHT routing reliability (peer discovery, partition recovery)
- ‚úÖ Store atomicity (crash safety, snapshot consistency)
- ‚úÖ Message integrity (signature validation, anti-replay)
- ‚úÖ Clean async behavior (no deadlocks, proper backpressure)

**If any lower layer is unstable, MLS becomes catastrophically brittle.**

---

## üìä **PROGRESS TRACKER**

**Total Tests:** 37  
**Completed:** 13  
**In Progress:** 5 (Router Security Tests)  
**Blocked:** 0

**Coverage by Subsystem:**

- [x] Identity: 7/7 (100%) ‚úÖ COMPLETE
- [‚ö°] Router: 1/5 (20%) ‚ö° IN PROGRESS - Test 2.1 complete
- [ ] DHT: 0/5 (0%)
- [x] CRDT: 6/6 (100%) ‚úÖ COMPLETE
- [ ] Store: 0/5 (0%)
- [ ] Integration: 0/9 (0%)

**Last Updated:** 2025-12-01  
**Current Phase:** Phase 2 - Router Security Tests (2.1 complete, 2.2 in progress)  
**Next Phase:** DHT Resilience Tests (3.1-3.5)

---

# 1Ô∏è‚É£ **IDENTITY: CRYPTOGRAPHIC SANITY TESTS** (7 tests)

**Location:** `src/core_identity/tests/crypto_sanity_tests.rs`

These are required before a single MLS key can be generated.

---

### ‚úÖ 1.1 Key Upgrade Test

**File:** `test_key_upgrade_rotation`  
**Priority:** CRITICAL  
**Estimated Time:** 2-3 hours  
**Status:** ‚úÖ COMPLETE

When a device rotates its global identity keypair:

- [ ] New keypair should be stored
- [ ] Old keypair must be removed (or marked as revoked)
- [ ] All per-channel keys must be re-signed
- [ ] Identity fingerprint must stay stable (unless using stable hash of nickname+device secret)
- [ ] CRDT signatures with new key validate correctly
- [ ] Historical signatures with old key still validate (if archival)

**Test Scenario:**

```rust
1. Create identity with keypair V1
2. Sign 10 CRDT operations
3. Rotate to keypair V2
4. Verify old signatures still valid (if archived)
5. Verify new operations sign with V2
6. Verify fingerprint unchanged
7. Verify per-channel keys re-signed
```

**Edge Cases:**

- Rotation during active channel session
- Rotation while offline
- Rotation with pending unsigned operations

---

### ‚úÖ 1.2 Key Revocation Test

**File:** `test_key_revocation_enforcement`  
**Priority:** CRITICAL  
**Estimated Time:** 1-2 hours  
**Status:** ‚úÖ COMPLETE

If a private key is deleted/revoked:

- [ ] Operations fail fast with clear error
- [ ] System must refuse to sign CRDT updates
- [ ] Router refuses to authenticate RPCs
- [ ] Revocation status persists across restarts
- [ ] Export/import preserves revocation state

**Test Scenario:**

```rust
1. Create identity
2. Sign operations successfully
3. Revoke keypair
4. Attempt to sign ‚Üí expect failure
5. Attempt RPC auth ‚Üí expect rejection
6. Restart system
7. Verify revocation persists
```

---

### ‚úÖ 1.3 Device Identity Isolation Test

**File:** `test_device_identity_isolation`  
**Priority:** HIGH  
**Estimated Time:** 2 hours  
**Status:** ‚úÖ COMPLETE

Two devices with same user identity:

- [ ] Should share global identity ID
- [ ] But each has **its own device key**
- [ ] Signatures from device A ‚â† signatures from device B
- [ ] Device A cannot decrypt device B's channel keys
- [ ] Metadata tracks both devices separately

**Test Scenario:**

```rust
1. Create user identity
2. Create device A with user identity
3. Create device B with same user identity
4. Verify user_id matches
5. Verify device keys differ
6. Sign with A ‚Üí verify B signature differs
7. Verify A cannot access B's channel pseudonyms
```

---

### ‚úÖ 1.4 Channel-Pseudonym Unlinkability Test

**File:** `test_channel_pseudonym_unlinkability`  
**Priority:** HIGH  
**Estimated Time:** 1-2 hours  
**Status:** ‚úÖ COMPLETE

Ensure no accidental equality or derivability:

- [ ] `channel_keypair_A.private != channel_keypair_B.private`
- [ ] `hash(pubA) != hash(pubB)`
- [ ] Not derivable from global key (unless intentional KDF)
- [ ] No statistical correlation between channel keys
- [ ] No accidental reuse of nonces/salts

**Test Scenario:**

```rust
1. Create 100 channel pseudonyms
2. Verify all private keys unique
3. Verify all public key hashes unique
4. Test derivability from global key (must fail)
5. Statistical test: key distribution is uniform
```

---

### ‚úÖ 1.5 Import/Export Keystore Test

**File:** `test_keystore_import_export_roundtrip`  
**Priority:** HIGH  
**Estimated Time:** 2-3 hours  
**Status:** ‚úÖ COMPLETE

Export keystore ‚Üí delete ‚Üí import ‚Üí system must:

- [ ] Restore all identities
- [ ] Restore all pseudonyms
- [ ] Restore all metadata (device names, etc.)
- [ ] Signature continuity remains valid
- [ ] No corruptions or missing keys
- [ ] Encrypted export uses strong crypto
- [ ] Import validates integrity

**Test Scenario:**

```rust
1. Create identity with 10 channel pseudonyms
2. Sign 50 operations
3. Export keystore (encrypted)
4. Delete all keys from memory
5. Import keystore
6. Verify all keys restored
7. Verify old signatures still validate
8. Verify new signatures work
```

---

### ‚úÖ 1.6 Corrupt Keystore Test

**File:** `test_keystore_corruption_handling`  
**Priority:** MEDIUM  
**Estimated Time:** 1 hour  
**Status:** ‚úÖ COMPLETE

Corrupt a random byte in the keystore file:

- [ ] Load should fail with deterministic error
- [ ] System should fall back into safe-degraded mode ("zero identities loaded")
- [ ] Error message guides user to recovery options
- [ ] No panic or crash
- [ ] Partial keys not loaded (all-or-nothing)

**Test Scenario:**

```rust
1. Create keystore
2. Export to file
3. Corrupt random byte
4. Attempt import
5. Verify graceful failure
6. Verify error message helpful
7. Verify system in safe state
```

---

### ‚úÖ 1.7 Key Expiration Test

**File:** `test_key_expiration_enforcement`  
**Priority:** MEDIUM  
**Estimated Time:** 1-2 hours  
**Status:** ‚úÖ COMPLETE

If a key is marked expired:

- [ ] Device must not use it for signing
- [ ] Signing operations fail with "key expired" error
- [ ] Rotation workflow triggered automatically
- [ ] Expired keys archived (not deleted) for historical validation
- [ ] Migrations help rotate all dependent keys

**Test Scenario:**

```rust
1. Create identity with expiration = now + 1 second
2. Sign operations successfully
3. Wait for expiration
4. Attempt signing ‚Üí expect failure
5. Verify rotation workflow triggered
6. Verify old key archived
```

---

---

# 2Ô∏è‚É£ **ROUTER SUBSYSTEM MISSION-CRITICAL TESTS** (5 tests)

**Location:** `src/core_router/tests/security_tests.rs`

---

### ‚úÖ 2.1 Noise Handshake Downgrade Test

**File:** `test_noise_handshake_downgrade_protection`  
**Priority:** CRITICAL  
**Estimated Time:** 2-3 hours  
**Status:** ‚úÖ COMPLETE

**Implemented tests:**

- Valid Noise_XX handshake succeeds
- Malformed handshake data rejected
- Plaintext injection rejected
- Random garbage rejected
- No Established event on failed handshake

Force an attacker to attempt:

- [ ] Downgrade to Noise_NN (no identity)
- [ ] Downgrade to Noise_X (weaker auth)
- [ ] Downgrade to plaintext
- [ ] Version rollback attack

Expected: handshake aborts with clear error.

**Test Scenario:**

```rust
1. Normal Noise_XX handshake ‚Üí success
2. Attacker forces Noise_NN ‚Üí reject
3. Attacker forces Noise_X ‚Üí reject
4. Attacker sends plaintext ‚Üí reject
5. Verify connection closed
6. Verify no state leaked
```

---

### ‚òê 2.2 Onion Path-Leak Test

**File:** `test_onion_routing_privacy`  
**Priority:** CRITICAL  
**Estimated Time:** 3-4 hours  
**Status:** ‚è≠Ô∏è DEFERRED - Requires OnionRouter circuit building API

Ensure the relay never learns:

- [ ] Sender IP (via instrumented fake relay)
- [ ] Final recipient ID
- [ ] Message content
- [ ] Correlation between requests

Test by instrumenting a fake relay:

```rust
relay sees only: encrypted payload + next-hop pubkey
relay must not observe sender global key
```

**Test Scenario:**

```rust
1. Create 3-hop onion path
2. Instrument middle relay to log all data
3. Send message
4. Verify relay log shows:
   - ‚úÖ Encrypted payload
   - ‚úÖ Next-hop pubkey only
   - ‚ùå No sender info
   - ‚ùå No recipient info
   - ‚ùå No plaintext
```

---

### ‚òê 2.3 Path Failure & Retry Test

**File:** `test_onion_path_failure_recovery`  
**Priority:** HIGH  
**Estimated Time:** 2-3 hours  
**Status:** ‚è≠Ô∏è DEFERRED - Requires RouterHandle path management + reputation

Simulate:

- [ ] Relay offline (connection refused)
- [ ] Relay tampering with packet (invalid MAC)
- [ ] Relay returning invalid ciphertext
- [ ] Relay timeout (no response)

Router must:

- [ ] Rebuild a new path
- [ ] Retry up to N times
- [ ] Surface structured error (not panic)
- [ ] Track failed relay reputation

**Test Scenario:**

```rust
1. Build path [A ‚Üí B ‚Üí C]
2. Make B go offline
3. Verify path rebuild
4. Make C tamper with packet
5. Verify detection + rebuild
6. Exhaust retry limit
7. Verify graceful failure
```

---

### ‚úÖ 2.4 RPC Request-ID Replay Test

**File:** `test_rpc_request_id_replay_protection`  
**Priority:** HIGH  
**Estimated Time:** 1-2 hours  
**Status:** ‚úÖ COMPLETE

**Implemented features:**

- Added anti-replay protection to RpcProtocol
- Seen request IDs tracked with timestamps
- TTL-based pruning (5min default)
- Background cleanup task
- Duplicate requests rejected with error code -32600

**Test validates:**

- First request accepted and processed
- Replay of same ID rejected
- Different request IDs work independently
- Seen requests count tracked correctly

Send the same "RPC request ID" twice:

- [ ] Second one rejected
- [ ] No replay in handler
- [ ] Anti-replay map prunes after TTL
- [ ] Works across router restarts (if persisted)

**Test Scenario:**

```rust
1. Send RPC with ID=123 ‚Üí success
2. Send RPC with ID=123 again ‚Üí rejected
3. Wait for TTL expiry
4. Send RPC with ID=123 ‚Üí success (allowed after TTL)
5. Verify no double-execution
```

---

### ‚òê 2.5 Connection-Flood Test

**File:** `test_connection_flood_protection`  
**Priority:** MEDIUM  
**Estimated Time:** 2 hours  
**Status:** ‚è≠Ô∏è DEFERRED - Requires RouterHandle with rate limiting

Simulate 200 fake nodes trying to connect:

- [ ] Handshake fails early for malicious nodes
- [ ] Node is not DoS-ed
- [ ] Rate limits trigger
- [ ] Memory usage bounded
- [ ] CPU usage reasonable

**Test Scenario:**

```rust
1. Spawn 200 fake connection attempts
2. Verify rate limiting kicks in
3. Verify memory usage < threshold
4. Verify legitimate connections still work
5. Verify cleanup after flood stops
```

---

---

# 3Ô∏è‚É£ **DHT SUBSYSTEM MISSION-CRITICAL TESTS** (5 tests)

**Location:** `src/core_dht/tests/resilience_tests.rs`

---

### ‚òê 3.1 Partition + Heal Merge Test

**File:** `test_dht_partition_heal_convergence`  
**Priority:** CRITICAL  
**Estimated Time:** 3-4 hours

Simulate:

- [ ] Two DHT halves isolated (network partition)
- [ ] Both mutate same key concurrently
- [ ] Reconverge after partition heals

Expected:

- [ ] CRDT convergence
- [ ] Routing table rebuilt
- [ ] Stale peers removed cleanly
- [ ] No duplicate providers
- [ ] No lost data

**Test Scenario:**

```rust
1. Create 10-node DHT
2. Partition into [1-5] and [6-10]
3. Both sides PUT same key with different values
4. Heal partition
5. Wait for convergence
6. Verify CRDT merge correct
7. Verify routing tables consistent
```

---

### ‚òê 3.2 Randomized Gossip Fuzz Test

**File:** `test_dht_gossip_fuzz`  
**Priority:** HIGH  
**Estimated Time:** 4-5 hours

Random inject 10,000 operations:

- [ ] Random keys
- [ ] Random TTLs
- [ ] Random gossip fanout
- [ ] Random offline peers

After 30s of simulated time:

- [ ] `assert(all nodes contain same CRDT state)`
- [ ] `assert(no tombstone leaks)`
- [ ] `assert(no duplicate keys)`
- [ ] `assert(routing tables converged)`

**Test Scenario:**

```rust
1. Create 20-node DHT
2. Generate 10,000 random ops:
   - PUT, GET, DELETE
   - Random keys (0-1000)
   - Random TTLs (1s-100s)
3. Random node failures (20% offline)
4. Run for 30s simulated time
5. Verify convergence
6. Verify no anomalies
```

---

### ‚òê 3.3 Provider-Expiration Test

**File:** `test_dht_provider_expiration`  
**Priority:** MEDIUM  
**Estimated Time:** 2 hours

Expire records:

- [ ] Provider goes offline
- [ ] Providers table should prune
- [ ] Queries should return _new_ providers only
- [ ] Stale providers not returned
- [ ] Re-publication extends TTL

**Test Scenario:**

```rust
1. Node A provides key K with TTL=5s
2. Query for K ‚Üí A is provider
3. Wait 6s (TTL expired)
4. Query for K ‚Üí A not in results
5. Node B provides K
6. Query for K ‚Üí only B in results
```

---

### ‚òê 3.4 Adversarial DHT Peer Test

**File:** `test_dht_malicious_peer_handling`  
**Priority:** HIGH  
**Estimated Time:** 3-4 hours

A malicious node:

- [ ] Returns random garbage instead of value
- [ ] Claims to be provider but isn't
- [ ] Returns inconsistent routing entries
- [ ] Sends malformed RPC responses

Expected:

- [ ] Reject malformed responses
- [ ] Update peer reputation
- [ ] Eject from routing table
- [ ] Query succeeds via alternate path

**Test Scenario:**

```rust
1. Create DHT with 1 malicious node M
2. M returns garbage for GET requests
3. Verify client rejects response
4. Verify M reputation drops
5. M claims false provider status
6. Verify client validates claims
7. Verify M ejected after threshold
```

---

### ‚òê 3.5 Deep-Routing Test

**File:** `test_dht_deep_routing_correctness`  
**Priority:** MEDIUM  
**Estimated Time:** 2-3 hours

Generate a 200-bit random ID and query for it:

- [ ] Full XOR distance walk performed
- [ ] No short-cuts
- [ ] No infinite loops
- [ ] Hops <= expected log(n)
- [ ] Converges to closest peers

**Test Scenario:**

```rust
1. Create 1000-node DHT
2. Generate random 200-bit ID
3. Query for ID
4. Instrument routing to log hops
5. Verify hop count <= log2(1000) ‚âà 10
6. Verify no loops
7. Verify converged to K closest peers
```

---

---

# 4Ô∏è‚É£ **CRDT SUBSYSTEM MISSION-CRITICAL TESTS** (6 tests)

**Location:** `src/core_identity/tests/crdt_mission_critical_tests.rs`

These are absolutely required before MLS integration because MLS depends on correct replicated state.

---

### ‚úÖ 4.1 Convergent Fuzz Test

**File:** `test_crdt_convergent_fuzz`  
**Priority:** CRITICAL  
**Estimated Time:** 4-5 hours  
**Status:** ‚úÖ COMPLETE

Generate:

- [ ] 300 OR-Set ops (add, remove, re-add)
- [ ] 300 LWW ops (set with random timestamps)
- [ ] 500 GList ops (insert, delete, move)

Random ordering across 5 replicas.

Expected:

- [ ] `assert(replica1.state == replica2.state == ...)`
- [ ] No tombstone leaks
- [ ] No divergence
- [ ] Deterministic final state

**Test Scenario:**

```rust
1. Create 5 replicas
2. Generate 1100 random ops
3. Shuffle ops differently per replica
4. Apply all ops
5. Merge all replicas
6. Verify exact state equality
7. Verify no memory leaks
```

---

### ‚úÖ 4.2 Massive Deletion Test

**File:** `test_crdt_massive_deletion`  
**Priority:** HIGH  
**Estimated Time:** 2 hours  
**Status:** ‚úÖ COMPLETE

Delete same item 100 times from OR-Set:

- [ ] Must not resurrect deleted items
- [ ] Must not overflow storage
- [ ] Must not break causal ordering
- [ ] Tombstones don't leak indefinitely

**Test Scenario:**

```rust
1. Create OR-Set
2. Add element X with tag1
3. Delete X 100 times (different VCs)
4. Add X with tag2
5. Verify X present (new tag)
6. Verify old tag tombstoned
7. Verify storage bounded
```

---

### ‚úÖ 4.3 Causal-Reverse Test

**File:** `test_crdt_causal_ordering_clock_skew`  
**Priority:** CRITICAL  
**Estimated Time:** 2-3 hours  
**Status:** ‚úÖ COMPLETE

Create 200 messages with reversed timestamps (simulate clock skew):

- [ ] LWW must honor vector clocks, not wall-clock times
- [ ] Causal relationships preserved
- [ ] No lost updates

**Test Scenario:**

```rust
1. Replica A: VC=[A:1], TS=1000, value="old"
2. Replica B: VC=[A:1,B:1], TS=500, value="new"
3. Merge A and B
4. Verify "new" wins (higher VC, lower TS)
5. Test with 200 operations
6. Verify causal order respected
```

---

### ‚úÖ 4.4 Interleaving Edits Test

**File:** `test_crdt_interleaving_edits`  
**Priority:** HIGH  
**Estimated Time:** 3-4 hours  
**Status:** ‚úÖ COMPLETE

Multiple replicas modify:

- [ ] Name (LWW)
- [ ] Topic (LWW)
- [ ] Roles (OR-Map)
- [ ] Messages (GList)
- [ ] Membership (OR-Set)

All interleaved, out-of-order.

Expected: convergence.

**Test Scenario:**

```rust
1. Create 3 replicas
2. Replica A: edit name, add user, send message
3. Replica B: edit topic, change role, delete message
4. Replica C: edit name, remove user, send message
5. Interleave ops randomly
6. Merge all
7. Verify convergence
8. Verify no conflicts
```

---

### ‚úÖ 4.5 Counter Overflow Test

**File:** `test_crdt_vector_clock_overflow`  
**Priority:** MEDIUM  
**Estimated Time:** 1-2 hours  
**Status:** ‚úÖ COMPLETE

Force vector clock to reach max integer:

- [ ] No panic
- [ ] Saturate safely
- [ ] CRDT still merges cleanly
- [ ] Warning logged

**Test Scenario:**

```rust
1. Create VC with counter = u64::MAX - 10
2. Increment 20 times
3. Verify saturation at MAX
4. Verify no panic
5. Verify merge still works
6. Verify warning logged
```

---

### ‚úÖ 4.6 Byzantine Signature Test

**File:** `test_crdt_byzantine_signature_rejection`  
**Priority:** CRITICAL  
**Estimated Time:** 2-3 hours  
**Status:** ‚úÖ COMPLETE

Feed CRDT:

- [ ] Invalid signature
- [ ] Mismatched channel pseudonym
- [ ] Unsigned delta

Expected:

- [ ] Rejection
- [ ] Invariant: "no unsigned mutation can enter log"
- [ ] No state corruption

**Test Scenario:**

```rust
1. Create signed CRDT operation
2. Corrupt signature
3. Attempt apply ‚Üí expect rejection
4. Create op with wrong channel key
5. Attempt apply ‚Üí expect rejection
6. Create unsigned op
7. Attempt apply ‚Üí expect rejection
8. Verify state unchanged
```

---

---

# 5Ô∏è‚É£ **STORE SUBSYSTEM MISSION-CRITICAL TESTS** (5 tests)

**Location:** `src/core_store/tests/persistence_tests.rs`

---

### ‚òê 5.1 Snapshot Replay Test

**File:** `test_store_snapshot_replay`  
**Priority:** CRITICAL  
**Estimated Time:** 3-4 hours

Generate:

- [ ] 200 ops
- [ ] Snapshot
- [ ] 200 more ops
- [ ] Replay snapshot + deltas

Expected final state identical to original.

**Test Scenario:**

```rust
1. Apply 200 ops to store
2. Take snapshot S1
3. Apply 200 more ops
4. Final state = F
5. Restore from S1
6. Replay 200 ops
7. Verify state == F
8. Verify no duplicates
```

---

### ‚òê 5.2 Corrupt Snapshot Test

**File:** `test_store_corrupt_snapshot_handling`  
**Priority:** HIGH  
**Estimated Time:** 2 hours

Corrupt a random byte in snapshot:

- [ ] Fail gracefully
- [ ] System offers "rebuild from DHT" recovery option
- [ ] No panic
- [ ] Error message helpful

**Test Scenario:**

```rust
1. Create snapshot
2. Corrupt random byte
3. Attempt restore
4. Verify graceful failure
5. Verify recovery options shown
6. Verify state unchanged
```

---

### ‚òê 5.3 Anti-Entropy Roundtrip Test

**File:** `test_store_anti_entropy_convergence`  
**Priority:** CRITICAL  
**Estimated Time:** 3-4 hours

Two replicas:

- [ ] One fresh
- [ ] One full of data

Perform full anti-entropy cycle:

- [ ] New replica identical to original
- [ ] No double applies
- [ ] No missing ops
- [ ] Efficient (minimal transfer)

**Test Scenario:**

```rust
1. Replica A has 1000 ops
2. Replica B is empty
3. Run anti-entropy A‚ÜíB
4. Verify B state == A state
5. Verify op count == 1000
6. Verify no duplicates
7. Run anti-entropy B‚ÜíA (no-op)
8. Verify A unchanged
```

---

### ‚òê 5.4 Slow-Store Simulation Test

**File:** `test_store_slow_io_backpressure`  
**Priority:** MEDIUM  
**Estimated Time:** 2-3 hours

Inject artificial delay of 500ms in store:

- [ ] CRDT layer does not deadlock
- [ ] Router backpressure works
- [ ] Async tasks don't explode
- [ ] System remains responsive

**Test Scenario:**

```rust
1. Inject 500ms delay in store writes
2. Send 100 rapid operations
3. Verify no deadlock
4. Verify backpressure triggers
5. Verify memory bounded
6. Verify system responsive
```

---

### ‚òê 5.5 Store Persistence Under Crash Test

**File:** `test_store_crash_recovery`  
**Priority:** CRITICAL  
**Estimated Time:** 3-4 hours

Simulate power loss after write start but before fsync:

- [ ] Atomicity preserved
- [ ] No partial record
- [ ] Recovery OK
- [ ] No data loss

**Test Scenario:**

```rust
1. Start write operation
2. Simulate crash before fsync
3. Restart store
4. Verify either:
   - Write fully persisted, OR
   - Write fully rolled back
5. No partial/corrupt state
6. Next write succeeds
```

---

---

# 6Ô∏è‚É£ **INTEGRATION & CROSS-SUBSYSTEM TESTS** (9 tests)

**Location:** `src/tests/integration_tests.rs`

---

### ‚òê 6.1 Full Stack Message Roundtrip

**File:** `test_integration_full_message_roundtrip`  
**Priority:** CRITICAL  
**Estimated Time:** 4-5 hours

End-to-end test:

- [ ] Create 2 nodes
- [ ] Join same channel
- [ ] Send message A‚ÜíB via onion routing
- [ ] Store in CRDT
- [ ] Sync via DHT
- [ ] Verify delivery

---

### ‚òê 6.2 Multi-Device Sync Test

**File:** `test_integration_multi_device_sync`  
**Priority:** HIGH  
**Estimated Time:** 3-4 hours

User with 3 devices:

- [ ] Device A sends message
- [ ] Device B receives via DHT sync
- [ ] Device C joins later, syncs history
- [ ] All devices converge

---

### ‚òê 6.3 Offline-Then-Online Test

**File:** `test_integration_offline_online_sync`  
**Priority:** HIGH  
**Estimated Time:** 3 hours

- [ ] Device A offline for 1 hour
- [ ] Device B sends 100 messages
- [ ] Device A comes online
- [ ] Full sync occurs
- [ ] No messages lost

---

### ‚òê 6.4 Channel Migration Test

**File:** `test_integration_channel_migration`  
**Priority:** MEDIUM  
**Estimated Time:** 3-4 hours

User leaves channel and joins new one:

- [ ] Old channel keys revoked
- [ ] New channel pseudonym created
- [ ] No key reuse
- [ ] Old messages still accessible (if archived)

---

### ‚òê 6.5 Concurrent Channel Operations

**File:** `test_integration_concurrent_channel_ops`  
**Priority:** HIGH  
**Estimated Time:** 3-4 hours

- [ ] 10 users concurrently edit topic
- [ ] 10 users concurrently send messages
- [ ] 5 users join/leave simultaneously
- [ ] All CRDTs converge
- [ ] No lost updates

---

### ‚òê 6.6 DHT Churn During Sync

**File:** `test_integration_dht_churn_resilience`  
**Priority:** MEDIUM  
**Estimated Time:** 3 hours

- [ ] 50% of DHT nodes go offline
- [ ] Channel sync continues
- [ ] New nodes join and sync
- [ ] Eventual consistency achieved

---

### ‚òê 6.7 Identity Rotation During Active Session

**File:** `test_integration_identity_rotation_live`  
**Priority:** HIGH  
**Estimated Time:** 3-4 hours

- [ ] User rotates key during active chat
- [ ] New messages sign with new key
- [ ] Old messages still validate
- [ ] No interruption to peers

---

### ‚òê 6.8 Store Compaction During Load

**File:** `test_integration_store_compaction_under_load`  
**Priority:** MEDIUM  
**Estimated Time:** 2-3 hours

- [ ] System under message load
- [ ] Trigger store compaction
- [ ] No messages lost
- [ ] Performance acceptable

---

### ‚òê 6.9 Byzantine Peer in DHT

**File:** `test_integration_byzantine_peer_isolation`  
**Priority:** HIGH  
**Estimated Time:** 3-4 hours

- [ ] Malicious peer in routing path
- [ ] Returns corrupt data
- [ ] System isolates peer
- [ ] Routing rebuilt
- [ ] Messages still delivered

---

---

# üìã **IMPLEMENTATION GUIDELINES**

## Test Organization

```
spacepanda-core/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core_identity/tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crypto_sanity_tests.rs          # 1.1-1.7
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crdt_mission_critical_tests.rs  # 4.1-4.6
‚îÇ   ‚îú‚îÄ‚îÄ core_router/tests/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security_tests.rs               # 2.1-2.5
‚îÇ   ‚îú‚îÄ‚îÄ core_dht/tests/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ resilience_tests.rs             # 3.1-3.5
‚îÇ   ‚îú‚îÄ‚îÄ core_store/tests/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ persistence_tests.rs            # 5.1-5.5
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ       ‚îî‚îÄ‚îÄ integration_tests.rs            # 6.1-6.9
```

## Test Naming Convention

```rust
#[test]
fn test_{subsystem}_{feature}_{scenario}() {
    // Arrange
    // Act
    // Assert
}
```

## Required Test Infrastructure

### Fixtures

- [ ] `MockIdentityStore` - In-memory identity storage
- [ ] `MockRouter` - Simulated router with delay injection
- [ ] `MockDHT` - Controllable DHT for partition simulation
- [ ] `MockStore` - Crash-safe store simulator
- [ ] `TestClock` - Controllable time for expiration tests

### Utilities

- [ ] `fuzz::random_ops()` - Random CRDT operation generator
- [ ] `network::partition()` - Network partition simulator
- [ ] `corruption::flip_bit()` - Data corruption injector
- [ ] `async::with_timeout()` - Timeout wrapper for async tests

## Success Criteria

**Before MLS integration is allowed:**

- [ ] All 37 tests implemented
- [ ] All 37 tests passing
- [ ] 100% pass rate on CI
- [ ] Code coverage > 80% for tested subsystems
- [ ] Performance benchmarks stable
- [ ] Documentation updated

---

# üö® **BLOCKERS & DEPENDENCIES**

## Current Blockers

- None (greenfield)

## External Dependencies

- `tokio` for async test harness
- `proptest` for fuzz testing
- `tempfile` for filesystem tests
- `mockall` (optional) for mocking

## Internal Dependencies

- Stable CRDT implementation (‚úÖ DONE)
- Basic DHT implementation (‚ö†Ô∏è IN PROGRESS)
- Router with Noise (‚ö†Ô∏è PARTIAL)
- Store persistence layer (‚ö†Ô∏è PARTIAL)

---

# üìÖ **TIMELINE ESTIMATE**

**Total Estimated Time:** 90-110 hours

**Breakdown:**

- Identity tests: 12-15 hours
- Router tests: 12-15 hours
- DHT tests: 14-18 hours
- CRDT tests: 16-20 hours
- Store tests: 13-17 hours
- Integration tests: 23-27 hours

**Recommended Pace:**

- Week 1: Identity + Router (24-30h)
- Week 2: DHT + CRDT (30-38h)
- Week 3: Store + Integration (36-44h)

**DEADLINE:** All tests complete before any `core_mls` work begins.

---

# ‚úÖ **COMPLETION CHECKLIST**

## Phase 1: Foundation (Identity + CRDT)

- [x] All identity tests passing ‚úÖ
- [x] All CRDT tests passing ‚úÖ
- [x] CI green ‚úÖ
- [ ] Code review complete

## Phase 2: Security Layer (Router)

- [ ] All router tests passing ‚ö° IN PROGRESS
- [ ] CI green
- [ ] Code review complete

## Phase 3: Network Resilience (DHT)

- [ ] All DHT tests passing
- [ ] Fuzz tests run for 24h without failure
- [ ] Code review complete

## Phase 4: Persistence (Store)

- [ ] All store tests passing
- [ ] Crash recovery verified
- [ ] Performance acceptable
- [ ] Code review complete

## Phase 5: Integration

- [ ] All integration tests passing
- [ ] Multi-device sync verified
- [ ] Byzantine peer handling verified
- [ ] Final code review

## Phase 6: Sign-Off

- [ ] All 37 tests passing (13/37 complete)
- [ ] CI fully green
- [ ] Documentation complete
- [ ] **READY FOR MLS INTEGRATION**

---

## üìù **CURRENT SESSION NOTES**

**What's Complete:**

- ‚úÖ Identity cryptographic tests (7/7) - Production-grade Ed25519/X25519 with replay protection
- ‚úÖ CRDT mission-critical tests (6/6) - Convergence, Byzantine resistance, causal ordering
- ‚úÖ Router test 2.1 (Noise handshake downgrade protection) - 5 attack scenarios validated
- ‚úÖ Router test 2.4 (RPC replay protection) - Anti-replay feature implemented + tested
- ‚úÖ 676 tests passing in full suite (was 674, +2 router tests)

**What's In Progress:**

- ‚è≠Ô∏è Router tests 2.2, 2.3, 2.5 deferred pending API completion
  - 2.2 needs OnionRouter circuit building
  - 2.3 needs RouterHandle path management + reputation
  - 2.5 needs RouterHandle rate limiting
- ‚ö° Ready to move to DHT or Store tests

**Files Modified This Session:**

- `src/core_router/tests/security_tests.rs` - Implemented 2 tests (2.1 and 2.4), ~280 lines total
- `src/core_router/rpc_protocol.rs` - Added anti-replay protection with TTL-based pruning
- `TESTING_TODO_BEFORE_MLS.md` - Updated progress tracker

**Next Steps:**

1. ~~Implement test_noise_handshake_downgrade_protection~~ ‚úÖ DONE
2. ~~Implement test_rpc_request_id_replay_protection~~ ‚úÖ DONE
3. Move to DHT resilience tests (5 tests) OR Store persistence tests (5 tests)
4. Return to router tests 2.2/2.3/2.5 after router APIs stabilize
5. Implement integration tests (9 tests)

---

# üìù **NOTES**

- Tests should be **deterministic** (use seeded RNG)
- Tests should be **fast** (<100ms each for unit tests)
- Integration tests can be slower (<10s each)
- Use `#[ignore]` for very slow tests (fuzz, etc.)
- All tests must pass on CI before merge
- No test should require external services
- Use `tempfile` for filesystem isolation

---

**Last Updated:** 2025-12-01  
**Maintained By:** Core Development Team  
**Status:** BLOCKING MLS INTEGRATION
